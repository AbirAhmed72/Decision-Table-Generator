{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9-7rKgfPNe2V"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbirAhmed72/Decision-Table-Generator/blob/decision_table_feature/decision_table_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Library Imports**"
      ],
      "metadata": {
        "id": "9-7rKgfPNe2V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "id": "5uFNrdhjC72r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "from word2number import w2n\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inputs**"
      ],
      "metadata": {
        "id": "hMzafIw8hjIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sentences = [\n",
        "#     \"If the working hours are 48 or less then give normal salary.\",\n",
        "#     \"The rate of the salary is 1.25 times if the working hours exceed 48 on normal working days.\",\n",
        "#     \"If the working days are holidays or Sundays then the rate of the salary is 2.00 times.\"\n",
        "# ]\n",
        "sentences = [\n",
        "    \"If the order is from DGS&D then the discount is 10%.\",\n",
        "    \"The discount is 15% if the order is from agents and the amount is more than Rs 50000.\",\n",
        "    \"The discount is 10% if the order is from retailer and the amount is more than Rs 50000.\",\n",
        "    \"If the amount is between Rs 20000 to Rs 50000 and the order is from agents then the discount is 12%.\",\n",
        "    \"If the amount is between Rs 20000 to Rs 50000 and the order is from retailer then the discount is 8%.\",\n",
        "    \"If the amount is less than Rs 20000 and the order is from agents then the discount is 8%.\",\n",
        "    \"The discount is 5% if the order is from retailer and the amount is less than Rs 20000.\",\n",
        "    \"The discount is 10% if item is furniture.\",\n",
        "]"
      ],
      "metadata": {
        "id": "x-cA8q5ehox3"
      },
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Condition and action stubs generation**"
      ],
      "metadata": {
        "id": "4mQn-gUkKLfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_single_conditions(mixed_conditions):\n",
        "  mixed_conditions=[item.split(' and ') for item in mixed_conditions]\n",
        "  unique_conditions=[]\n",
        "  for conditions in mixed_conditions:\n",
        "    for condition in conditions:\n",
        "      unique_conditions.append(condition)\n",
        "  return unique_conditions\n",
        "\n",
        "def filter_unique(single_conditions):\n",
        "  unique_conditions = set()\n",
        "  for condition in single_conditions:\n",
        "    unique_conditions.add(condition)\n",
        "  return list(unique_conditions)\n",
        "\n",
        "def clean_data(dataset):\n",
        "  dataset=[data.lower() for data in dataset]\n",
        "  translator = str.maketrans('', '', string.punctuation)\n",
        "  return [data.translate(translator) for data in dataset]\n",
        "\n",
        "def cleaning_action_stubs(mixed_actions):\n",
        "  return filter_unique(clean_data(mixed_actions))\n",
        "\n",
        "def cleaning_condition_stubs(mixed_conditions):\n",
        "  single_conditions= create_single_conditions(clean_data(mixed_conditions))\n",
        "  return filter_unique(single_conditions)\n",
        "\n",
        "def cleaning_stubs(mixed_conditions,mixed_actions):\n",
        "  return cleaning_condition_stubs(mixed_conditions),cleaning_action_stubs(mixed_actions)\n",
        "\n",
        "def get_stubs(sentences):\n",
        "  condition_stub = []\n",
        "  action_stub = []\n",
        "  for sentence in sentences:\n",
        "      words = sentence.split()\n",
        "      if words[0].lower() == 'if':\n",
        "          condition_index = sentence.lower().index('if') + 2\n",
        "          then_index = sentence.lower().index('then')\n",
        "          condition_stub.append(sentence[condition_index:then_index].strip())\n",
        "          action_stub.append(sentence[then_index + 4:].strip())\n",
        "      else:\n",
        "          if_index = sentence.lower().index('if')\n",
        "          condition_stub.append(sentence[if_index + 2:].strip())\n",
        "          action_stub.append(sentence[:if_index].strip())\n",
        "\n",
        "  conditions,actions =(cleaning_stubs(condition_stub,action_stub))\n",
        "  return conditions,actions\n"
      ],
      "metadata": {
        "id": "3CcBR8loDvj9"
      },
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rule Generation**"
      ],
      "metadata": {
        "id": "sD1o6ZUL0ii9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_conditions_for_a_rule(mixed_condition,condition_stubs):\n",
        "  conditions_for_a_rule=[]\n",
        "\n",
        "  conditions=split_mixed_stub(mixed_condition)\n",
        "  for condition in conditions:\n",
        "    condition=condition.strip()\n",
        "    for index, condition_stub in enumerate(condition_stubs):\n",
        "      if condition in condition_stub:\n",
        "        conditions_for_a_rule.append(index)\n",
        "  return conditions_for_a_rule\n",
        "\n",
        "def get_actions_for_a_rule(mixed_action,action_stubs):\n",
        "  actions_for_a_rule=[]\n",
        "\n",
        "  actions=split_mixed_stub(mixed_action)\n",
        "  for action in actions:\n",
        "    action=action.strip()\n",
        "    for index, action_stub in enumerate(action_stubs):\n",
        "      if action in action_stub:\n",
        "        actions_for_a_rule.append(index)\n",
        "  return actions_for_a_rule\n",
        "\n",
        "def parse_sentence(sentence,if_then):\n",
        "  condition_index = sentence.index('if')\n",
        "  if(if_then):\n",
        "    then_index = sentence.index('then')\n",
        "    mixed_condition=sentence[condition_index+2:then_index].strip()\n",
        "    mixed_action=sentence[then_index + 4:].strip()\n",
        "  else:\n",
        "    mixed_condition=sentence[condition_index+2:].strip()\n",
        "    mixed_action=sentence[:condition_index].strip()\n",
        "  return mixed_condition,mixed_action\n",
        "\n",
        "def get_condition_and_action_from_sentence(sentence):\n",
        "  sentence=''.join(clean_data(sentence))\n",
        "  words = sentence.split()\n",
        "\n",
        "  if words[0] == 'if':\n",
        "    mixed_condition,mixed_action=parse_sentence(sentence,True)\n",
        "  else:\n",
        "    mixed_condition,mixed_action=parse_sentence(sentence,False)\n",
        "  return mixed_condition,mixed_action\n",
        "\n",
        "def split_mixed_stub(mixed_condition):\n",
        "  return mixed_condition.split('and')\n",
        "\n",
        "def create_rules(sentences,condition_stubs,action_stubs):\n",
        "\n",
        "  rules={}\n",
        "  rule=1\n",
        "  for sentence in sentences:\n",
        "\n",
        "    mixed_condition,mixed_action =  get_condition_and_action_from_sentence(sentence)\n",
        "    conditions_for_a_rule =   get_conditions_for_a_rule(mixed_condition,condition_stubs)\n",
        "    actions_for_a_rule =   get_actions_for_a_rule(mixed_action,action_stubs)\n",
        "\n",
        "    rules[rule]=[conditions_for_a_rule,actions_for_a_rule]\n",
        "    rule+=1\n",
        "  return rules\n"
      ],
      "metadata": {
        "id": "ok0bpxWCEraI"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Table Generation**"
      ],
      "metadata": {
        "id": "zedyih34Dde-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_column_headers(rules):\n",
        "  column_headers = []\n",
        "  for i in rules:\n",
        "    column_header=\"R\"+str(i)\n",
        "    column_headers.append(column_header)\n",
        "  return column_headers\n",
        "\n",
        "def make_row_headers(condition_stubs,action_stubs):\n",
        "  row_headers = []\n",
        "\n",
        "  for index,condition_stub in enumerate(condition_stubs):\n",
        "    row_header=\"C\"+str(index+1)+\":\"+str(condition_stub)\n",
        "    row_headers.append(row_header)\n",
        "\n",
        "  for index,action_stub in enumerate(action_stubs):\n",
        "    row_header=\"A\"+str(index+1)+\":\"+str(action_stub)\n",
        "    row_headers.append(row_header)\n",
        "\n",
        "  return row_headers\n",
        "\n",
        "def make_table(condition_stubs,action_stubs,rules):\n",
        "  column_headers=make_column_headers(rules)\n",
        "  row_headers=make_row_headers(condition_stubs,action_stubs)\n",
        "  table = pd.DataFrame(columns=column_headers, index=row_headers)\n",
        "  return table\n",
        "\n",
        "def initialize_table(table):\n",
        "  for row in table.index:\n",
        "      if(row.startswith('C')):\n",
        "        for col in table.columns:\n",
        "                table.at[row, col] = 'I'\n",
        "      else:\n",
        "        for col in table.columns:\n",
        "          table.at[row, col] = ' '\n",
        "  return table\n",
        "\n",
        "def adjust_dependent_entries(table,condition,condition_stubs,col):\n",
        "  dependencies=dependency_dictionary[find_variable_name(condition_stubs[condition])]\n",
        "  for dependency_condition in dependencies:\n",
        "    for row in table.index:\n",
        "      if(row.startswith('C') and dependency_condition!=condition+1 and int(row[1])==dependency_condition):\n",
        "        table.at[row,col] ='F'\n",
        "\n",
        "def set_condition_stubs_entries(table,rules,condition_stubs):\n",
        "  for i in range(1,len(table.columns)+1):\n",
        "    condition_set=(rules[i][0])\n",
        "    for condition in condition_set:\n",
        "      for row in table.index:\n",
        "        if(row.startswith('C') and int(row[1])==condition+1):\n",
        "          col=table.columns[i-1]\n",
        "          table.at[row,col] ='T'\n",
        "          adjust_dependent_entries(table,condition,condition_stubs,col)\n",
        "  return table\n",
        "\n",
        "def set_action_stubs_entries(table,rules):\n",
        "  for i in range(1,len(table.columns)+1):\n",
        "    action_set=(rules[i][1])\n",
        "    for action in action_set:\n",
        "      for row in table.index:\n",
        "        if(row.startswith('A') and int(row[1])==action+1):\n",
        "          col=table.columns[i-1]\n",
        "          table.at[row,col] ='x'\n",
        "  return table\n",
        "\n",
        "def find_independent_rows(table,number_of_conditions,rules):\n",
        "  independent_rows=[]\n",
        "  for column_name, conditions in table.items():\n",
        "    number_of_truths=0\n",
        "    number_of_ignores=0\n",
        "    for condition in conditions:\n",
        "      if(condition=='T'): number_of_truths+=1\n",
        "      elif(condition=='I'): number_of_ignores+=1\n",
        "    if(number_of_truths==1 and number_of_ignores==number_of_conditions-1):\n",
        "      independent_rows.append(rules[int(column_name[1])][0][0])\n",
        "  return independent_rows\n",
        "\n",
        "def optimize_table(table,number_of_conditions,rules):\n",
        "  independent_rows=find_independent_rows(table,number_of_conditions,rules)\n",
        "  for independent_row in independent_rows:\n",
        "    i=0\n",
        "    for row_name, row_data in table.iterrows():\n",
        "      if(i==independent_row):\n",
        "        for col_index,data in enumerate(row_data):\n",
        "          if(data!='T'): table.iat[independent_row, col_index]='F'\n",
        "      i+=1\n",
        "\n",
        "def generate_table(condition_stubs,action_stubs,rules):\n",
        "  table=initialize_table(make_table(condition_stubs,action_stubs,rules))\n",
        "  table=set_action_stubs_entries(table,rules)\n",
        "  table=set_condition_stubs_entries(table,rules,condition_stubs)\n",
        "  optimize_table(table,len(condition_stubs),rules)\n",
        "  return table\n",
        "\n",
        "def printDetails(condition_stubs,action_stubs,rules,table):\n",
        "  print(\"Rules are: \")\n",
        "  for rule in rules:\n",
        "\n",
        "    mixed_condition=\"\"\n",
        "    for condition in rules[rule][0]:\n",
        "      mixed_condition+=condition_stubs[condition]\n",
        "      mixed_condition+=','\n",
        "\n",
        "\n",
        "    mixed_action=\"\"\n",
        "    for action in rules[rule][1]:\n",
        "      mixed_action+=action_stubs[action]\n",
        "      mixed_action+=','\n",
        "    print(str(rule)+\":\"+\"If \"+mixed_condition+\"then \"+mixed_action)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DpvxfoUdDhUu"
      },
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Case generation**\n",
        "## Task-1 (DONE)\n",
        "We need to parse the condition and action like this:<br>input: the order is from dgsd\n",
        "<br>output: order=dgsd\n",
        "\n",
        "<br>input: the order is from agents\n",
        "<br>output: order=agents\n",
        "\n",
        "<br>input: the order is from retailer\n",
        "<br>output: order=retailer\n",
        "\n",
        "<br>input: the amount is more than rs 50000\n",
        "<br>output: amount>=50000\n",
        "\n",
        "\n",
        "<br>input: the amount is between rs 20000 to rs 50000\n",
        "<br>output: amount>=20000 &&  amount<=50000\n",
        "\n",
        "\n",
        "<br>input: the amount is less than rs 20000\n",
        "<br>output: amount<=20000\n",
        "\n",
        "<br>input: item is furniture\n",
        "<br>output: item=furniture\n",
        "\n",
        "<br>input: the discount is 15\n",
        "<br>output: discount=15\n",
        "\n",
        "<br>\n",
        "\n",
        "## Task-2 (DONE)\n",
        "\n",
        "From there we need to find out the dependency/toggling of the variables and we will optimize our table\n",
        "\n",
        "##Task-3\n",
        "\n",
        "Finally we will generate the test cases after we are finished with optimizing our decision table\n",
        "\n"
      ],
      "metadata": {
        "id": "B32Y3wY0uBOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_determinant(sentences):\n",
        "  pruned_sentences=[]\n",
        "  for sentence in sentences:\n",
        "    doc = nlp(sentence)\n",
        "    sentence = \" \".join([token.text for token in doc if token.pos_ != \"DET\"])\n",
        "    pruned_sentences.append(sentence)\n",
        "  return pruned_sentences\n",
        "\n",
        "def describe_parts_of_speech(sentence):\n",
        "  parts_of_speech={}\n",
        "  doc = nlp(sentence)\n",
        "  for token in doc:\n",
        "    parts_of_speech[token.text]=token.dep_\n",
        "  return parts_of_speech\n",
        "\n",
        "def noun_list(sentence):\n",
        "  nouns=[]\n",
        "  doc = nlp(sentence)\n",
        "  for token in doc:\n",
        "    if(token.pos_=='NOUN'):\n",
        "      nouns.append(token.text)\n",
        "  return nouns\n",
        "\n",
        "def find_variable_name(sentence):\n",
        "  doc = nlp(sentence)\n",
        "  for token in doc:\n",
        "    if(token.pos_=='NOUN'):\n",
        "      return token.text\n",
        "  return 'No Noun Found'\n",
        "\n",
        "def find_patterns(sentence):\n",
        "  matcher = Matcher(nlp.vocab)\n",
        "\n",
        "  between_pattern = [\n",
        "      {\"LOWER\": \"between\"},\n",
        "      {\"OP\": \"*\"},\n",
        "      {\"LOWER\": \"to\"}\n",
        "  ]\n",
        "\n",
        "  more_than_pattern = [\n",
        "      {\"LOWER\": \"more\"},\n",
        "      {\"LOWER\": \"than\"}\n",
        "  ]\n",
        "  less_than_pattern = [\n",
        "      {\"LOWER\": \"less\"},\n",
        "      {\"LOWER\": \"than\"}\n",
        "  ]\n",
        "\n",
        "  is_are_pattern = [\n",
        "      {\"LOWER\": {\"IN\": [\"is\", \"are\"]},\n",
        "      }\n",
        "  ]\n",
        "\n",
        "  matcher.add(\"is_are\", [is_are_pattern])\n",
        "  matcher.add(\"between_to\", [between_pattern])\n",
        "  matcher.add(\"more_than\", [more_than_pattern])\n",
        "  matcher.add(\"less_than\", [less_than_pattern])\n",
        "\n",
        "  doc = nlp(sentence)\n",
        "  matches = matcher(doc)\n",
        "  matcher_names=[]\n",
        "  if matches:\n",
        "    for match_id, start, end in matches:\n",
        "        matched_text = doc[start:end].text\n",
        "        matcher_names.append(doc.vocab.strings[match_id])\n",
        "\n",
        "\n",
        "  return (matcher_names)\n",
        "\n",
        "def find_sign(sentence):\n",
        "  sign=\"\"\n",
        "\n",
        "  patterns=find_patterns(sentence)\n",
        "  for pattern in patterns:\n",
        "    if(pattern=='is_are'):\n",
        "      sign+='='\n",
        "    elif(pattern=='more_than'):\n",
        "      sign+='>'\n",
        "    elif(pattern=='less_than'):\n",
        "      sign+='<'\n",
        "    elif(pattern=='between_to'):\n",
        "      temp=[]\n",
        "      doc= nlp(sentence)\n",
        "      for token in doc:\n",
        "        if(token.tag_=='CD'): temp.append(w2n.word_to_num(token.text))\n",
        "      sign+=str(temp)\n",
        "  if sign==\"\": return 'No Sign Found'\n",
        "  else : return sign\n",
        "\n",
        "def find_value_of_a_variable(sentence):\n",
        "  value=[]\n",
        "  doc=nlp(sentence)\n",
        "  if 'between' not in sentence:\n",
        "    for token in doc:\n",
        "      if (token.dep_=='pobj' or token.dep_=='dobj' or token.dep_=='nummod'or token.dep_=='attr') :\n",
        "        value.append(token.text)\n",
        "    return str(value)\n",
        "  return ''\n",
        "\n",
        "def convert_to_expression(sentence):\n",
        "  # patterns = [\n",
        "  #   (r'is between (\\d+) (to|and) (\\d+)', r'\\1 < amount < \\3'),\n",
        "  #   (r'is between (\\d+) and (\\d+)', r'<\\1 and >\\2'),\n",
        "  #   (r'is between (\\d+) to (\\d+)', r'<\\1 and >\\2'),\n",
        "\n",
        "  #   (r'are between (\\d+) and (\\d+)', r'<\\1 and >\\2'),\n",
        "  #   (r'are between (\\d+) to (\\d+)', r'<\\1 and >\\2'),\n",
        "\n",
        "  #   (r'\\bor less\\b', '<='),\n",
        "  #   (r'\\bless than or equal to\\b', '<='),\n",
        "  #   (r'\\bless than\\b', '<'),\n",
        "\n",
        "  #   (r'\\bor more\\b', '>='),\n",
        "  #   (r'\\bmore than or equal to\\b', '>='),\n",
        "  #   (r'\\bmore than\\b', '>'),\n",
        "\n",
        "  #   (r'\\bor greater\\b', '>='),\n",
        "  #   (r'\\bgreater than or equal to\\b', '>='),\n",
        "  #   (r'\\bgreater than\\b', '>'),\n",
        "\n",
        "\n",
        "  #   (r'\\bis not equal to\\b', '!='),\n",
        "  #   (r'\\bis equal to\\b', '='),\n",
        "  #   (r'\\bis\\b', '='),\n",
        "\n",
        "  #   (r'\\bare not equal to\\b', '!='),\n",
        "  #   (r'\\bare equal to\\b', '='),\n",
        "  #   (r'\\bare\\b', '='),\n",
        "  # ]\n",
        "\n",
        "  expression=''\n",
        "  expression+=find_variable_name(sentence)\n",
        "  expression+=find_sign(sentence)\n",
        "  expression+=find_value_of_a_variable(sentence)\n",
        "  return expression\n",
        "\n",
        "def get_expressions(condition_stubs,action_stubs):\n",
        "  condition_stubs=prune_determinant(condition_stubs)\n",
        "  action_stubs=prune_determinant(action_stubs)\n",
        "  condition_stubs_expressions=[]\n",
        "  action_stubs_expressions=[]\n",
        "  for condition in condition_stubs:\n",
        "    condition_stubs_expressions.append(convert_to_expression(condition))\n",
        "  for action in action_stubs:\n",
        "    action_stubs_expressions.append(convert_to_expression(action))\n",
        "  return  condition_stubs_expressions,action_stubs_expressions\n",
        "\n",
        "def find_unique_variables(condition_stubs_expressions):\n",
        "  unique_variable = {}\n",
        "  for expression in condition_stubs_expressions:\n",
        "      variable, value = expression.split('=')\n",
        "      unique_variable[variable] = value\n",
        "  unique_variables=list(unique_variable.keys())\n",
        "  return unique_variables\n",
        "\n",
        "def create_dependency_dictionary(condition_stubs,condition_stubs_expressions):\n",
        "  unique_variables=find_unique_variables(condition_stubs_expressions)\n",
        "  dependencies={}\n",
        "  for variable in unique_variables:\n",
        "    conditions=[]\n",
        "    i=1\n",
        "    for condition in condition_stubs:\n",
        "      if(variable==find_variable_name(condition)):\n",
        "        conditions.append(i)\n",
        "      i+=1\n",
        "    dependencies[variable]=conditions\n",
        "  return dependencies\n"
      ],
      "metadata": {
        "id": "lfOzDH04y9xV"
      },
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_test_case_table(table):\n",
        "  for row in table.index:\n",
        "    for col in table.columns:\n",
        "      table.at[row, col] = 'any'\n",
        "  return table\n",
        "\n",
        "def make_test_case_table(dependency_dictionary,rules):\n",
        "  column_headers=list(dependency_dictionary.keys())\n",
        "  column_headers.append('Expected Output')\n",
        "\n",
        "  row_headers=[]\n",
        "  for i in range(1,len(rules)+1):\n",
        "    row_headers.append(i)\n",
        "  test_case_table = pd.DataFrame(columns=column_headers, index=row_headers)\n",
        "  return initialize_test_case_table(test_case_table)\n",
        "\n",
        "def fill_test_case_inputs(test_case_table,condition_stubs_expressions,rules):\n",
        "  for index,rule in enumerate(rules.values()):\n",
        "    row_label=index+1\n",
        "    for condition in rule[0]:\n",
        "      splited_expression=condition_stubs_expressions[condition].split('=')\n",
        "      col_label=(splited_expression[0])\n",
        "      test_case_table.at[index+1,col_label]=splited_expression[1]\n",
        "  return test_case_table\n",
        "\n",
        "def fill_expected_output_section(test_case_table,action_stubs,rules):\n",
        "  last_column=test_case_table.columns[-1]\n",
        "  index=1\n",
        "  for rule in rules.values():\n",
        "    test_case_table.at[index, last_column] = (action_stubs[rule[1][0]])\n",
        "    index+=1\n",
        "  return (test_case_table)\n",
        "\n",
        "def generate_test_case_table(rules,condition_stubs,action_stubs):\n",
        "  condition_stubs_expressions,action_stubs_expressions=get_expressions(condition_stubs,action_stubs)\n",
        "  dependency_dictionary=create_dependency_dictionary(condition_stubs,condition_stubs_expressions)\n",
        "  test_case_table =make_test_case_table(dependency_dictionary,rules)\n",
        "  test_case_table=fill_test_case_inputs(test_case_table,condition_stubs_expressions,rules)\n",
        "  test_case_table=fill_expected_output_section(test_case_table,action_stubs,rules)\n",
        "  return test_case_table\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t29SvpXy7ulS"
      },
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Driver**"
      ],
      "metadata": {
        "id": "OuDF6dHn5Mb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "condition_stubs,action_stubs=get_stubs(sentences)\n",
        "rules=create_rules(sentences,condition_stubs,action_stubs)\n",
        "table=generate_table(condition_stubs,action_stubs,rules)\n",
        "test_case_table=generate_test_case_table(rules,condition_stubs,action_stubs)\n",
        "\n",
        "printDetails(condition_stubs,action_stubs,rules,table)\n",
        "print(table)\n",
        "print(test_case_table)"
      ],
      "metadata": {
        "id": "Zrbhr3xd5O6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86228111-ed81-4dca-f02c-9b809d5b869a"
      },
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rules are: \n",
            "1:If the order is from dgsd,then the discount is 10,\n",
            "2:If the order is from agents,the amount is more than rs 50000,then the discount is 15,\n",
            "3:If the order is from retailer,the amount is more than rs 50000,then the discount is 10,\n",
            "4:If the amount is between rs 20000 to rs 50000,the order is from agents,then the discount is 12,\n",
            "5:If the amount is between rs 20000 to rs 50000,the order is from retailer,then the discount is 8,\n",
            "6:If the amount is less than rs 20000,the order is from agents,then the discount is 8,\n",
            "7:If the order is from retailer,the amount is less than rs 20000,then the discount is 5,\n",
            "8:If item is furniture,then the discount is 10,\n",
            "                                              R1 R2 R3 R4 R5 R6 R7 R8\n",
            "C1:the amount is between rs 20000 to rs 50000  I  F  F  T  T  F  F  I\n",
            "C2:the order is from agents                    F  T  F  T  F  T  F  I\n",
            "C3:the order is from retailer                  F  F  T  F  T  F  T  I\n",
            "C4:the amount is less than rs 20000            I  F  F  F  F  T  T  I\n",
            "C5:item is furniture                           F  F  F  F  F  F  F  T\n",
            "C6:the order is from dgsd                      T  F  F  F  F  F  F  I\n",
            "C7:the amount is more than rs 50000            I  T  T  F  F  F  F  I\n",
            "A1:the discount is 8                                       x  x      \n",
            "A2:the discount is 15                             x                  \n",
            "A3:the discount is 5                                             x   \n",
            "A4:the discount is 10                          x     x              x\n",
            "A5:the discount is 12                                   x            \n",
            "             amount         order           item     Expected Output\n",
            "1               any      ['dgsd']            any  the discount is 10\n",
            "2  >['rs', '50000']    ['agents']            any  the discount is 15\n",
            "3  >['rs', '50000']  ['retailer']            any  the discount is 10\n",
            "4    [20000, 50000]    ['agents']            any  the discount is 12\n",
            "5    [20000, 50000]  ['retailer']            any   the discount is 8\n",
            "6        <['20000']    ['agents']            any   the discount is 8\n",
            "7        <['20000']  ['retailer']            any   the discount is 5\n",
            "8               any           any  ['furniture']  the discount is 10\n"
          ]
        }
      ]
    }
  ]
}