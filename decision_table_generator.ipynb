{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9-7rKgfPNe2V",
        "RwqThja5Okno"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbirAhmed72/Decision-Table-Generator/blob/decision_table_feature/decision_table_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Library Imports**"
      ],
      "metadata": {
        "id": "9-7rKgfPNe2V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "5uFNrdhjC72r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inputs**"
      ],
      "metadata": {
        "id": "hMzafIw8hjIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sentences = [\n",
        "#     \"If the working hours are 48 or less then give normal salary.\",\n",
        "#     \"The rate of the salary is 1.25 times if the working hours exceed 48 on normal working days.\",\n",
        "#     \"If the working days are holidays or Sundays then the rate of the salary is 2.00 times.\"\n",
        "# ]\n",
        "sentences = [\n",
        "    \"If the order is from DGS&D then the discount is 10%.\",\n",
        "    \"The discount is 15% if the order is from agents and the amount is more than Rs 50000.\",\n",
        "    \"The discount is 10% if the order is from retailer and the amount is more than Rs 50000.\",\n",
        "    \"If the amount is between Rs 20000 to Rs 50000 and the order is from agents then the discount is 12%.\",\n",
        "    \"If the amount is between Rs 20000 to Rs 50000 and the order is from retailer then the discount is 8%.\",\n",
        "    \"If the amount is less than Rs 20000 and the order is from agents then the discount is 8%.\",\n",
        "    \"The discount is 5% if the order is from retailer and the amount is less than Rs 20000.\",\n",
        "    \"The discount is 10% if item is furniture.\",\n",
        "]"
      ],
      "metadata": {
        "id": "x-cA8q5ehox3"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Condition and action stubs generation**"
      ],
      "metadata": {
        "id": "4mQn-gUkKLfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_single_conditions(mixed_conditions):\n",
        "  mixed_conditions=[item.split(' and ') for item in mixed_conditions]\n",
        "  unique_conditions=[]\n",
        "  for conditions in mixed_conditions:\n",
        "    for condition in conditions:\n",
        "      unique_conditions.append(condition)\n",
        "  return unique_conditions\n",
        "\n",
        "def filter_unique(single_conditions):\n",
        "  unique_conditions = set()\n",
        "  for condition in single_conditions:\n",
        "    unique_conditions.add(condition)\n",
        "  return list(unique_conditions)\n",
        "\n",
        "def clean_data(dataset):\n",
        "  dataset=[data.lower() for data in dataset]\n",
        "  translator = str.maketrans('', '', string.punctuation)\n",
        "  return [data.translate(translator) for data in dataset]\n",
        "\n",
        "def cleaning_action_stubs(mixed_actions):\n",
        "  return filter_unique(clean_data(mixed_actions))\n",
        "\n",
        "def cleaning_condition_stubs(mixed_conditions):\n",
        "  single_conditions= create_single_conditions(clean_data(mixed_conditions))\n",
        "  return filter_unique(single_conditions)\n",
        "\n",
        "def cleaning_stubs(mixed_conditions,mixed_actions):\n",
        "  return cleaning_condition_stubs(mixed_conditions),cleaning_action_stubs(mixed_actions)\n",
        "\n",
        "def get_stubs(sentences):\n",
        "  condition_stub = []\n",
        "  action_stub = []\n",
        "  for sentence in sentences:\n",
        "      words = sentence.split()\n",
        "      if words[0].lower() == 'if':\n",
        "          condition_index = sentence.lower().index('if') + 2\n",
        "          then_index = sentence.lower().index('then')\n",
        "          condition_stub.append(sentence[condition_index:then_index].strip())\n",
        "          action_stub.append(sentence[then_index + 4:].strip())\n",
        "      else:\n",
        "          if_index = sentence.lower().index('if')\n",
        "          condition_stub.append(sentence[if_index + 2:].strip())\n",
        "          action_stub.append(sentence[:if_index].strip())\n",
        "\n",
        "  conditions,actions =(cleaning_stubs(condition_stub,action_stub))\n",
        "  return conditions,actions\n"
      ],
      "metadata": {
        "id": "3CcBR8loDvj9"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rule Generation**"
      ],
      "metadata": {
        "id": "sD1o6ZUL0ii9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_conditions_for_a_rule(mixed_condition,condition_stubs):\n",
        "  conditions_for_a_rule=[]\n",
        "\n",
        "  conditions=split_mixed_stub(mixed_condition)\n",
        "  for condition in conditions:\n",
        "    condition=condition.strip()\n",
        "    for index, condition_stub in enumerate(condition_stubs):\n",
        "      if condition in condition_stub:\n",
        "        conditions_for_a_rule.append(index)\n",
        "  return conditions_for_a_rule\n",
        "\n",
        "def get_actions_for_a_rule(mixed_action,action_stubs):\n",
        "  actions_for_a_rule=[]\n",
        "\n",
        "  actions=split_mixed_stub(mixed_action)\n",
        "  for action in actions:\n",
        "    action=action.strip()\n",
        "    for index, action_stub in enumerate(action_stubs):\n",
        "      if action in action_stub:\n",
        "        actions_for_a_rule.append(index)\n",
        "  return actions_for_a_rule\n",
        "\n",
        "def parse_sentence(sentence,if_then):\n",
        "  condition_index = sentence.index('if')\n",
        "  if(if_then):\n",
        "    then_index = sentence.index('then')\n",
        "    mixed_condition=sentence[condition_index+2:then_index].strip()\n",
        "    mixed_action=sentence[then_index + 4:].strip()\n",
        "  else:\n",
        "    mixed_condition=sentence[condition_index+2:].strip()\n",
        "    mixed_action=sentence[:condition_index].strip()\n",
        "  return mixed_condition,mixed_action\n",
        "\n",
        "def get_condition_and_action_from_sentence(sentence):\n",
        "  sentence=''.join(clean_data(sentence))\n",
        "  words = sentence.split()\n",
        "\n",
        "  if words[0] == 'if':\n",
        "    mixed_condition,mixed_action=parse_sentence(sentence,True)\n",
        "  else:\n",
        "    mixed_condition,mixed_action=parse_sentence(sentence,False)\n",
        "  return mixed_condition,mixed_action\n",
        "\n",
        "def split_mixed_stub(mixed_condition):\n",
        "  return mixed_condition.split('and')\n",
        "\n",
        "def create_rules(sentences,condition_stubs,action_stubs):\n",
        "\n",
        "  rules={}\n",
        "  rule=1\n",
        "  for sentence in sentences:\n",
        "\n",
        "    mixed_condition,mixed_action =  get_condition_and_action_from_sentence(sentence)\n",
        "    conditions_for_a_rule =   get_conditions_for_a_rule(mixed_condition,condition_stubs)\n",
        "    actions_for_a_rule =   get_actions_for_a_rule(mixed_action,action_stubs)\n",
        "\n",
        "    rules[rule]=[conditions_for_a_rule,actions_for_a_rule]\n",
        "    rule+=1\n",
        "  return rules\n"
      ],
      "metadata": {
        "id": "ok0bpxWCEraI"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Table Generation**"
      ],
      "metadata": {
        "id": "zedyih34Dde-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_column_headers(rules):\n",
        "  column_headers = []\n",
        "  for i in rules:\n",
        "    column_header=\"R\"+str(i)\n",
        "    column_headers.append(column_header)\n",
        "  return column_headers\n",
        "\n",
        "def make_row_headers(condition_stubs,action_stubs):\n",
        "  row_headers = []\n",
        "\n",
        "  for index,condition_stub in enumerate(condition_stubs):\n",
        "    row_header=\"C\"+str(index+1)+\":\"+str(condition_stub)\n",
        "    row_headers.append(row_header)\n",
        "\n",
        "  for index,action_stub in enumerate(action_stubs):\n",
        "    row_header=\"A\"+str(index+1)+\":\"+str(action_stub)\n",
        "    row_headers.append(row_header)\n",
        "\n",
        "  return row_headers\n",
        "\n",
        "def make_table(condition_stubs,action_stubs,rules):\n",
        "  column_headers=make_column_headers(rules)\n",
        "  row_headers=make_row_headers(condition_stubs,action_stubs)\n",
        "  table = pd.DataFrame(columns=column_headers, index=row_headers)\n",
        "  return table\n",
        "\n",
        "def initialize_table(table):\n",
        "  for row in table.index:\n",
        "      if(row.startswith('C')):\n",
        "        for col in table.columns:\n",
        "                table.at[row, col] = 'F'\n",
        "      else:\n",
        "        for col in table.columns:\n",
        "          table.at[row, col] = ' '\n",
        "  return table\n",
        "\n",
        "def set_condition_stubs_entries(table,rules):\n",
        "  for i in range(1,len(table.columns)+1):\n",
        "    condition_set=(rules[i][0])\n",
        "    for condition in condition_set:\n",
        "      for row in table.index:\n",
        "        if(row.startswith('C') and int(row[1])==condition+1):\n",
        "          col=table.columns[i-1]\n",
        "          table.at[row,col] ='T'\n",
        "  return table\n",
        "\n",
        "def set_action_stubs_entries(table,rules):\n",
        "  for i in range(1,len(table.columns)+1):\n",
        "    action_set=(rules[i][1])\n",
        "    for action in action_set:\n",
        "      for row in table.index:\n",
        "        if(row.startswith('A') and int(row[1])==action+1):\n",
        "          col=table.columns[i-1]\n",
        "          table.at[row,col] ='x'\n",
        "  return table\n",
        "\n",
        "def generate_table(condition_stubs,action_stubs,rules):\n",
        "  table=initialize_table(make_table(condition_stubs,action_stubs,rules))\n",
        "  table=set_action_stubs_entries(table,rules)\n",
        "  table=set_condition_stubs_entries(table,rules)\n",
        "  return table\n",
        "\n",
        "def printDetails(condition_stubs,action_stubs,rules,table):\n",
        "  print(\"Rules are: \")\n",
        "  for rule in rules:\n",
        "\n",
        "    mixed_condition=\"\"\n",
        "    for condition in rules[rule][0]:\n",
        "      mixed_condition+=condition_stubs[condition]\n",
        "      mixed_condition+=','\n",
        "\n",
        "\n",
        "    mixed_action=\"\"\n",
        "    for action in rules[rule][1]:\n",
        "      mixed_action+=action_stubs[action]\n",
        "      mixed_action+=','\n",
        "    print(str(rule)+\":\"+\"If \"+mixed_condition+\"then \"+mixed_action)\n",
        "\n",
        "\n",
        "  print()\n",
        "  print(table)\n"
      ],
      "metadata": {
        "id": "DpvxfoUdDhUu"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Case generation**\n",
        "## Task-1\n",
        "We need to parse the condition and action like this:<br>input: the order is from dgsd\n",
        "<br>output: order=dgsd\n",
        "\n",
        "<br>input: the order is from agents\n",
        "<br>output: order=agents\n",
        "\n",
        "<br>input: the order is from retailer\n",
        "<br>output: order=retailer\n",
        "\n",
        "<br>input: the amount is more than rs 50000\n",
        "<br>output: amount>=50000\n",
        "\n",
        "\n",
        "<br>input: the amount is between rs 20000 to rs 50000\n",
        "<br>output: amount>=20000 &&  amount<=50000\n",
        "\n",
        "\n",
        "<br>input: the amount is less than rs 20000\n",
        "<br>output: amount<=20000\n",
        "\n",
        "<br>input: item is furniture\n",
        "<br>output: item=furniture\n",
        "\n",
        "<br>input: the discount is 15\n",
        "<br>output: discount=15\n",
        "\n",
        "<br>\n",
        "\n",
        "## Task-2\n",
        "\n",
        "From there we need to find out the dependency/toggling of the variables and we will optimize our table\n",
        "\n",
        "##Task-3\n",
        "\n",
        "Finally we will generate the test cases after we are finished with optimizing our decision table\n",
        "\n"
      ],
      "metadata": {
        "id": "B32Y3wY0uBOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_determinant(sentences):\n",
        "\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  pruned_sentences=[]\n",
        "  for sentence in sentences:\n",
        "    doc = nlp(sentence)\n",
        "    sentence = \" \".join([token.text for token in doc if token.pos_ != \"DET\"])\n",
        "    pruned_sentences.append(sentence)\n",
        "  return pruned_sentences\n",
        "\n",
        "def describe_parts_of_speech(sentence):\n",
        "\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  parts_of_speech={}\n",
        "  doc = nlp(sentence)\n",
        "  for token in doc:\n",
        "    parts_of_speech[token.text]=token.pos_\n",
        "  return parts_of_speech\n",
        "\n",
        "def noun_list(sentence):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  nouns=[]\n",
        "  doc = nlp(sentence)\n",
        "  for token in doc:\n",
        "    if(token.pos_=='NOUN'):\n",
        "      nouns.append(token.text)\n",
        "  return nouns\n",
        "\n",
        "\n",
        "def convert_to_expression(sentences):\n",
        "  expression=''\n",
        "  return expression\n",
        "\n",
        "condition_stubs=prune_determinant(condition_stubs)\n",
        "for condition in condition_stubs:\n",
        "  print(describe_parts_of_speech(condition))"
      ],
      "metadata": {
        "id": "lfOzDH04y9xV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ead63b17-7be0-4117-f47f-2aa3e3211fda"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'order': 'NOUN', 'is': 'AUX', 'from': 'ADP', 'retailer': 'NOUN'}\n",
            "{'item': 'NOUN', 'is': 'AUX', 'furniture': 'NOUN'}\n",
            "{'amount': 'NOUN', 'is': 'AUX', 'less': 'ADJ', 'than': 'ADP', 'rs': 'ADJ', '20000': 'NUM'}\n",
            "{'order': 'NOUN', 'is': 'AUX', 'from': 'ADP', 'dgsd': 'NOUN'}\n",
            "{'amount': 'NOUN', 'is': 'AUX', 'between': 'ADP', 'rs': 'VERB', '20000': 'NUM', 'to': 'PART', '50000': 'NUM'}\n",
            "{'order': 'NOUN', 'is': 'AUX', 'from': 'ADP', 'agents': 'NOUN'}\n",
            "{'amount': 'NOUN', 'is': 'AUX', 'more': 'ADJ', 'than': 'ADP', 'rs': 'ADJ', '50000': 'NUM'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Driver**"
      ],
      "metadata": {
        "id": "OuDF6dHn5Mb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "condition_stubs,action_stubs=get_stubs(sentences)\n",
        "rules=create_rules(sentences,condition_stubs,action_stubs)\n",
        "table=generate_table(condition_stubs,action_stubs,rules)\n",
        "\n",
        "printDetails(condition_stubs,action_stubs,rules,table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrbhr3xd5O6Q",
        "outputId": "6fbc436e-e045-45ca-aca8-5acd71efacf9"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rules are: \n",
            "1:If the order is from dgsd,then the discount is 10,\n",
            "2:If the order is from agents,the amount is more than rs 50000,then the discount is 15,\n",
            "3:If the order is from retailer,the amount is more than rs 50000,then the discount is 10,\n",
            "4:If the amount is between rs 20000 to rs 50000,the order is from agents,then the discount is 12,\n",
            "5:If the amount is between rs 20000 to rs 50000,the order is from retailer,then the discount is 8,\n",
            "6:If the amount is less than rs 20000,the order is from agents,then the discount is 8,\n",
            "7:If the order is from retailer,the amount is less than rs 20000,then the discount is 5,\n",
            "8:If item is furniture,then the discount is 10,\n",
            "\n",
            "                                              R1 R2 R3 R4 R5 R6 R7 R8\n",
            "C1:the order is from retailer                  F  F  T  F  T  F  T  F\n",
            "C2:item is furniture                           F  F  F  F  F  F  F  T\n",
            "C3:the amount is less than rs 20000            F  F  F  F  F  T  T  F\n",
            "C4:the order is from dgsd                      T  F  F  F  F  F  F  F\n",
            "C5:the amount is between rs 20000 to rs 50000  F  F  F  T  T  F  F  F\n",
            "C6:the order is from agents                    F  T  F  T  F  T  F  F\n",
            "C7:the amount is more than rs 50000            F  T  T  F  F  F  F  F\n",
            "A1:the discount is 15                             x                  \n",
            "A2:the discount is 10                          x     x              x\n",
            "A3:the discount is 12                                   x            \n",
            "A4:the discount is 8                                       x  x      \n",
            "A5:the discount is 5                                             x   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import difflib\n",
        "\n",
        "sentence1 = \"the amount is more than rs 50000\"\n",
        "sentence2 = \"the amount is less than rs 20000\"\n",
        "\n",
        "similarity_percentage = difflib.SequenceMatcher(None, sentence1, sentence2).ratio()*100\n",
        "\n",
        "print(f\"Similarity Percentage: {similarity_percentage:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azqr41Ze46Rp",
        "outputId": "55adda10-1467-4bb4-8227-6c08477fbb87"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity Percentage: 87.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Your input sentence\n",
        "input_sentence = \"the working hours are 48 or less\"\n",
        "\n",
        "# Define custom rules to convert text to mathematical expressions\n",
        "conversion_rules = {\n",
        "    \"less than\": \"<\",\n",
        "    \"greater than\": \">\",\n",
        "    \"or\": \"or\",\n",
        "    \"and\": \"and\",\n",
        "    \"is\":\"=\",\n",
        "    \"are\":\"=\",\n",
        "}\n",
        "\n",
        "# Tokenize and process the input sentence\n",
        "doc = nlp(input_sentence)\n",
        "\n",
        "# Initialize an empty expression string\n",
        "math_expression = \"\"\n",
        "\n",
        "# Iterate through the tokens and apply custom rules\n",
        "for token in doc:\n",
        "    if token.text in conversion_rules:\n",
        "        math_expression += f\" {conversion_rules[token.text]} \"\n",
        "    elif token.is_digit:\n",
        "        math_expression += token.text\n",
        "    elif token.is_alpha:\n",
        "        math_expression += token.text  # Assuming variables as-is\n",
        "    else:\n",
        "        math_expression += token.text\n",
        "\n",
        "print(f\"Input: '{input_sentence}'\")\n",
        "print(f\"Mathematical Expression: {math_expression}\")\n"
      ],
      "metadata": {
        "id": "vEXBKD_7ASWi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}